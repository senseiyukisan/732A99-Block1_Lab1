---
title: "Computer lab 1 block 1"
author: "Tim Yuki Washio"
date: "11/10/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(glmnet)
```

# Assignment 3 - Linear regression and LASSO

```{r data preperation}
# Load data 
data = read.csv("data/tecator.csv")

# Split data into train and test set
n = dim(data)[1]
set.seed(12345)
id = sample(1:n, floor(n*0.5))
train = data[id,]
test = data[-id,]
```

## 1.
Assume that Fat can be modeled as a linear regression in which absorbance characteristics (Channels) are used as features. Report the underlying probabilistic model, fit the linear regression to the training data and estimate the training and test errors. Comment on the quality of fit and prediction and therefore on the quality of model.

*Probabilistic model*:
$$\hat{y} = \beta_0 +\sum_{i = 1}^{100} \beta_i*x_i + \epsilon \sim {\sf N}(\mu, \sigma^2)$$

```{r linreg, echo=F}
# Fitting the linear regression model
predictors <- paste("Channel", 1:100, sep="")
fmla <- as.formula(paste("Fat ~ ", paste(predictors, collapse= "+")))

fit = lm(fmla, data=data)
summary(fit)

# Estimating training and test errors
yhat = predict(fit, train)
train_mse = mean((train$Fat-yhat)^2)
train_mae = mean(abs(train$Fat-yhat))
train_rmse = sqrt(mean((train$Fat-yhat)^2))

y0hat = predict(fit, test)
test_mse = mean((test$Fat-y0hat)^2)
test_mae = mean(abs(test$Fat-y0hat))
test_rmse = sqrt(mean((test$Fat-y0hat)^2))

cat("Train error\nMSE: ", train_mse, "\nMAE: ", train_mae, "\nRMSE: ", train_rmse, "\n\nTest error\nMSE: ", test_mse, "\nMAE: ", test_mae, "\nRMSE: ", test_rmse)

fitted <- predict(fit, interval = "confidence")
```

Our loss-function (MSE) is showing quite a difference between the prediction of train and test set values. The MSE for the train set is ~0.56 while the MSE for the test set returns a value of ~1.01. Therefore, our model seems to be overfitting on the train data.

## 2.

$$\underset{\beta}{\operatorname{argmin}}\left[\sum_{i = 1}^{n}\left(Y_i-\beta_0-\sum_{j = 1}^{p}\beta_jX_{ji}\right)^2+\lambda\sum_{j = 1}^{p}|\beta_j|\right]$$

